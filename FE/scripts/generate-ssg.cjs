const puppeteer = require('puppeteer');
const fs = require('fs-extra');
const path = require('path');
const handler = require('serve-handler');
const http = require('http');
const axios = require('axios');

// --- 1. SETUP ENVIRONMENT & CONFIGS ---
const env = process.env.ENVIRONMENT || 'local';
console.log(`üåç Starting SSG for environment: ${env}`);

// Load config
const configPath = path.join(__dirname, `../public/configs/${env}.json`);
if (!fs.existsSync(configPath)) {
    console.error(`‚ùå Config file not found: ${configPath}`);
    process.exit(1);
}
const envConfig = JSON.parse(fs.readFileSync(configPath, 'utf-8'));
const TARGET_DOMAIN = envConfig.currentURL;

console.log(`üéØ Target Domain from config: ${TARGET_DOMAIN}`);

// --- CONFIGURATION ---
const DIST_DIR = path.join(__dirname, '../dist');
const PORT = 3000;
const LOCAL_BASE_URL = `http://localhost:${PORT}`;

// We start by reading the local index, as that is definitely generated by the build
const LOCAL_SITEMAP_INDEX = `${LOCAL_BASE_URL}/sitemap.xml`;

/**
 * Helper: Extract XML tags
 */
function extractTags(xml, tagName) {
    const regex = new RegExp(`<${tagName}>(.*?)<\/${tagName}>`, 'g');
    const matches = [];
    let match;
    while ((match = regex.exec(xml)) !== null) {
        matches.push(match[1]);
    }
    return matches;
}

/**
 * 2. Fetch and Parse Sitemaps
 */
async function getRoutesFromSitemap() {
    console.log('üîç Starting Sitemap Discovery...');
    const routes = new Set(['/']);

    try {
        console.log(`‚òÅÔ∏è  Fetching Local Index: ${LOCAL_SITEMAP_INDEX}`);
        const { data: indexXml } = await axios.get(LOCAL_SITEMAP_INDEX);

        const allLocs = extractTags(indexXml, 'loc');
        const subSitemaps = allLocs.filter(url => url.endsWith('.xml'));

        console.log(`üìã Found ${subSitemaps.length} sub-sitemaps.`);

        // Fetch sub-sitemaps (Try Local -> Fallback to Remote)
        await Promise.all(subSitemaps.map(async (subUrl) => {
            let xmlData = null;
            const localSubUrl = subUrl.replace(TARGET_DOMAIN, LOCAL_BASE_URL);

            // 1. Try Local Fetch
            try {
                const response = await axios.get(localSubUrl);
                xmlData = response.data;
            } catch (localErr) {
                // 2. Fallback to Remote Fetch (if file missing locally)
                console.warn(`   ‚ö†Ô∏è  Local fetch failed for ${path.basename(subUrl)}. Trying remote: ${subUrl}...`);
                try {
                    const response = await axios.get(subUrl);
                    xmlData = response.data;
                    console.log(`   ‚úÖ Fetched ${path.basename(subUrl)} from remote.`);
                } catch (remoteErr) {
                    console.error(`   ‚ùå Failed to fetch sitemap from both local and remote: ${subUrl}`);
                    return; // Skip this sitemap
                }
            }

            // 3. Parse URLs
            if (xmlData) {
                const urls = extractTags(xmlData, 'loc');
                urls.forEach(fullUrl => {
                    if (fullUrl.includes(TARGET_DOMAIN)) {
                        // Strip domain to get relative path
                        const relativePath = fullUrl.replace(TARGET_DOMAIN, '');
                        const normalizedPath = relativePath.startsWith('/') ? relativePath : `/${relativePath}`;
                        routes.add(normalizedPath);
                    }
                });
            }
        }));

    } catch (error) {
        console.error('‚ùå Critical Error fetching sitemap index:', error.message);
        console.log('‚ö†Ô∏è  Falling back to Homepage only.');
    }

    const finalRoutes = Array.from(routes);
    console.log(`‚úÖ Total pages to generate for ${env}: ${finalRoutes.length}`);
    return finalRoutes;
}

/**
 * 3. Start Local File Server
 */
function startLocalServer() {
    const server = http.createServer((request, response) => {
        return handler(request, response, {
            public: DIST_DIR,
            // CRITICAL FIX: Rewrite 404s to index.html so React loads!
            rewrites: [
                { source: '**', destination: '/index.html' }
            ]
        });
    });

    return new Promise((resolve) => {
        server.listen(PORT, () => {
            console.log(`üöÄ Build server running at ${LOCAL_BASE_URL}`);
            resolve(server);
        });
    });
}

/**
 * 4. Crawl a Single Page
 */
async function crawlPage(page, route) {
    const url = `${LOCAL_BASE_URL}${route}`;
    // Decode URI to ensure file system writes valid filenames (e.g. Hebrew chars)
    // Azure SWA usually expects URL-encoded file names on disk for matching,
    // BUT common FS tools might struggle. We will stick to the route exactly as it comes.

    // Construct file path.
    // NOTE: decodeURIComponent fixes weird folder names like "%D7%90" -> "◊ê"
    const safeRoute = decodeURIComponent(route);
    const filePath = route === '/'
        ? path.join(DIST_DIR, 'index.html')
        : path.join(DIST_DIR, safeRoute, 'index.html');

    try {
        await page.goto(url, { waitUntil: 'networkidle0', timeout: 60000 });

        // Increased timeout to 30s to be safe
        await page.waitForSelector('#root', { timeout: 30000 });

        const html = await page.content();

        await fs.ensureDir(path.dirname(filePath));
        await fs.writeFile(filePath, html);

    } catch (err) {
        console.error(`   ‚ùå Error generating ${route}: ${err.message}`);
    }
}

/**
 * Main Execution Flow
 */
(async () => {
    if (!fs.existsSync(DIST_DIR)) {
        console.error('‚ùå dist/ folder not found. Run npm run build first.');
        process.exit(1);
    }

    let server;
    let browser;

    try {
        server = await startLocalServer();
        const routes = await getRoutesFromSitemap();

        browser = await puppeteer.launch({
            headless: "new",
            args: ['--no-sandbox', '--disable-setuid-sandbox']
        });
        const page = await browser.newPage();

        console.log(`üï∑Ô∏è  Starting Crawl for ${env}...`);
        for (let i = 0; i < routes.length; i++) {
            const route = routes[i];
            if (i % 10 === 0) console.log(`[${i + 1}/${routes.length}] Processing...`);
            await crawlPage(page, route);
        }

        console.log('‚ú® SSG Generation Complete!');

    } catch (error) {
        console.error('‚ùå Fatal Error:', error);
        process.exit(1);
    } finally {
        if (browser) await browser.close();
        if (server) server.close();
    }
})();
