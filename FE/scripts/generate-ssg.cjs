const puppeteer = require('puppeteer');
const fs = require('fs-extra');
const path = require('path');
const handler = require('serve-handler');
const http = require('http');
const axios = require('axios');

// ==========================================
// 1. CONFIGURATION & ENVIRONMENT
// ==========================================

const env = process.env.ENVIRONMENT || 'local';
console.log(`üåç Starting SSG for environment: ${env}`);

// Load Environment Config
const configPath = path.join(__dirname, `../public/configs/${env}.json`);
if (!fs.existsSync(configPath)) {
    console.error(`‚ùå Config file not found: ${configPath}`);
    process.exit(1);
}
const envConfig = JSON.parse(fs.readFileSync(configPath, 'utf-8'));

// CONSTANTS
const TARGET_DOMAIN = envConfig.currentURL;         // e.g. "https://srm-staging..."
const DIST_DIR = path.join(__dirname, '../dist');
const PORT = 3000;
const LOCAL_BASE_URL = `http://localhost:${PORT}`;
const LOCAL_SITEMAP_INDEX = `${LOCAL_BASE_URL}/sitemap.xml`;

console.log(`üéØ Target Domain: ${TARGET_DOMAIN}`);
console.log(`üè† Local Build Server: ${LOCAL_BASE_URL}`);


// ==========================================
// 2. HELPER FUNCTIONS
// ==========================================

/**
 * Extracts content within <tagName>...</tagName> from XML string.
 * Used to avoid heavy XML parser dependencies.
 */
function extractTags(xml, tagName) {
    const regex = new RegExp(`<${tagName}>(.*?)<\/${tagName}>`, 'g');
    const matches = [];
    let match;
    while ((match = regex.exec(xml)) !== null) {
        matches.push(match[1]);
    }
    return matches;
}

/**
 * Fetch a sitemap XML from a URL (Local or Remote).
 * Returns the data or null if failed.
 */
async function fetchXml(url, description) {
    try {
        const { data } = await axios.get(url);
        return data;
    } catch (error) {
        // Only log warning if it's a remote fetch failure or explicit error
        if (error.response && error.response.status !== 404) {
            console.warn(`   ‚ö†Ô∏è  Error fetching ${description}: ${error.message}`);
        }
        return null;
    }
}


// ==========================================
// 3. SITEMAP DISCOVERY LOGIC
// ==========================================

/**
 * Core Logic:
 * 1. Get sitemap.xml from LOCAL (generated by build).
 * 2. Find sub-sitemaps (cards.xml, hpsitemap.xml).
 * 3. Try to fetch each sub-sitemap LOCALLY first.
 * 4. If Local 404s, fetch REMOTELY (Target Domain).
 * 5. Aggregate all page URLs.
 */
async function getRoutesToCrawl() {
    console.log('\nüîç --- Step 1: Discovering Pages ---');
    const routes = new Set(['/']); // Always include Home

    // 1. Fetch Local Index
    console.log(`   üìÑ Fetching Index from Local: ${LOCAL_SITEMAP_INDEX}`);
    const indexXml = await fetchXml(LOCAL_SITEMAP_INDEX, "Local Index");

    if (!indexXml) {
        console.error("   ‚ùå Failed to load local sitemap.xml. Ensure 'npm run sitemap:main' ran.");
        return Array.from(routes);
    }

    // 2. Extract Sub-Sitemaps
    const subSitemapUrls = extractTags(indexXml, 'loc').filter(u => u.endsWith('.xml'));
    console.log(`   üìã Found ${subSitemapUrls.length} sub-sitemaps.`);

    // 3. Process each Sub-Sitemap
    for (const originalUrl of subSitemapUrls) {
        let xmlData = null;
        const filename = path.basename(originalUrl);

        // Strategy: Try Local URL replacement first
        const localUrl = originalUrl.replace(TARGET_DOMAIN, LOCAL_BASE_URL);

        // A. Try Local Fetch
        // console.log(`   Trying local: ${localUrl}`); // Optional debug
        xmlData = await fetchXml(localUrl, `Local ${filename}`);

        if (xmlData) {
            console.log(`   ‚úÖ Loaded locally: ${filename}`);
        } else {
            // B. Fallback to Remote Fetch
            console.log(`   ‚ö†Ô∏è  Local missing. Fetching remote: ${originalUrl}`);
            xmlData = await fetchXml(originalUrl, `Remote ${filename}`);
            if (xmlData) console.log(`   ‚úÖ Loaded remotely: ${filename}`);
        }

        // C. Parse URLs from whichever source succeeded
        if (xmlData) {
            const pageUrls = extractTags(xmlData, 'loc');
            pageUrls.forEach(fullUrl => {
                // Normalize: strip domain to get relative path
                if (fullUrl.includes(TARGET_DOMAIN)) {
                    let relative = fullUrl.replace(TARGET_DOMAIN, '');
                    if (!relative.startsWith('/')) relative = `/${relative}`;
                    routes.add(relative);
                }
            });
        } else {
            console.error(`   ‚ùå Failed to load ${filename} from both Local and Remote.`);
        }
    }

    const finalRoutes = Array.from(routes);
    console.log(`   ‚úÖ Total unique pages found: ${finalRoutes.length}`);
    return finalRoutes;
}


// ==========================================
// 4. SERVER & CRAWLER LOGIC
// ==========================================

/**
 * Starts a local HTTP server serving the 'dist' directory.
 * CRITICAL: Rewrites 404s to index.html so React can load.
 */
function startLocalServer() {
    const server = http.createServer((req, res) => {
        return handler(req, res, {
            public: DIST_DIR,
            rewrites: [
                { source: '**', destination: '/index.html' }
            ]
        });
    });

    return new Promise((resolve) => {
        server.listen(PORT, () => {
            console.log(`\nüöÄ --- Step 2: Build Server Started ---`);
            console.log(`   Listening at ${LOCAL_BASE_URL}`);
            resolve(server);
        });
    });
}

/**
 * Crawls a single route, waits for React, and saves HTML.
 */
async function crawlPage(page, route) {
    const url = `${LOCAL_BASE_URL}${route}`;
    // decodeURIComponent ensures we write "◊ê" instead of "%D7%90" to disk
    const safeRoute = decodeURIComponent(route);

    const filePath = route === '/'
        ? path.join(DIST_DIR, 'index.html')
        : path.join(DIST_DIR, safeRoute, 'index.html');

    try {
        await page.goto(url, { waitUntil: 'networkidle0', timeout: 60000 });

        // Wait for React to mount content (Selector #root)
        await page.waitForSelector('#root', { timeout: 30000 });

        const html = await page.content();

        await fs.ensureDir(path.dirname(filePath));
        await fs.writeFile(filePath, html);

    } catch (err) {
        console.error(`   ‚ùå Error generating ${route}:`);
        console.error(`      ${err.message}`);
    }
}


// ==========================================
// 5. MAIN EXECUTION
// ==========================================

(async () => {
    // Sanity Check
    if (!fs.existsSync(DIST_DIR)) {
        console.error('‚ùå dist/ folder missing. Run build first.');
        process.exit(1);
    }

    let server;
    let browser;

    try {
        // 1. Start Server
        server = await startLocalServer();

        // 2. Discover Routes
        const routes = await getRoutesToCrawl();

        // 3. Launch Browser
        console.log(`\nüï∑Ô∏è  --- Step 3: Starting Crawl (${routes.length} pages) ---`);
        browser = await puppeteer.launch({
            headless: "new",
            args: ['--no-sandbox', '--disable-setuid-sandbox']
        });
        const page = await browser.newPage();

        // 4. Process Queue
        for (let i = 0; i < routes.length; i++) {
            const route = routes[i];

            // Progress Log
            if (i % 20 === 0 || i === routes.length - 1) {
                console.log(`   [${i + 1}/${routes.length}] Processing...`);
            }

            await crawlPage(page, route);
        }

        console.log('\n‚ú® SSG Generation Complete!');

    } catch (error) {
        console.error('\n‚ùå Fatal Error:', error);
        process.exit(1);
    } finally {
        if (browser) await browser.close();
        if (server) server.close();
    }
})();
